# -*- coding: utf-8 -*-
"""submission_predictive.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WYbrxTguxekL11TYtV7uH0y46zwYXtV1

# Import Library

Import library yang dibutuhkan.
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.preprocessing import LabelEncoder

from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression

from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import MinMaxScaler

from sklearn.metrics import confusion_matrix, classification_report
from sklearn.metrics import roc_auc_score

"""# Load Dataset

Dataset yang digunakan : [Crop Recommendation Dataset](https://www.kaggle.com/datasets/atharvaingle/crop-recommendation-dataset)
"""

# Load dataset dan menampilkan nya

df = pd.read_csv("../Dataset/crop_recommendation.csv")
df

"""# EDA"""

# Melihat informasi data

df.info()

# Memisahkan antara fitur kategorikal dan numerikal

categorical = ['label']
numericals = df.drop(columns = categorical, axis = 1).columns

# Melihat deskripsi fitur numerikal

df[numericals].describe()

"""## Error Value

Mengecek apakah ada nilai null atau kosong pada dataset kita.
"""

df.isnull().sum()

# Menghitung value error pada fitur numerikal (minus)

for i in (df[numericals]):
  misValue = (df[i] < 0).sum()
  print(f'Value error pada {i} :', misValue)

"""Dataset yang kita gunakan merupakan dataset yang bersih, sehingga kita tidak perlu melakukan cleaning pada dataset.

## Distribusi Data
"""

plt.figure(figsize=(12, 6))
sns.countplot(data=df, x='label', order=df['label'].value_counts().index)
plt.xticks(rotation=90)
plt.title('Crop Label Distribution')
plt.tight_layout()
plt.show()

"""Pada visualisasi distribusi `label` diatas, setiap label memiliki data sebanyak 100 data yang dimana distribusi tiap `label` seimbang.

## Check for outliers
"""

plt.figure(figsize=(16, 10))
for i, numerical in enumerate(numericals, 1):
    plt.subplot(3, 3, i)
    sns.boxplot(x=df[numerical])
    plt.title(f'{numerical} Outliers')
plt.tight_layout()
plt.show()

"""### IQR

Karena terdapat nilai yang dapat dikatakan sebagai outliers, maka kita akan mencoba membersihkan nya.
"""

df_clean = df.copy()

for col in numericals:
    Q1 = df_clean[col].quantile(0.25)
    Q3 = df_clean[col].quantile(0.75)
    IQR = Q3 - Q1

    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR

    df_clean = df_clean[(df_clean[col] >= lower_bound) & (df_clean[col] <= upper_bound)]

print(f"Original dataset shape: {df.shape}")
print(f"Cleaned dataset shape: {df_clean.shape}")

# Melihat distribusi setelah penghapusan outliers

plt.figure(figsize=(12, 6))
sns.countplot(data=df_clean, x='label', order=df['label'].value_counts().index)
plt.xticks(rotation=90)
plt.title('Crop Label Distribution')
plt.tight_layout()
plt.show()

"""Karena percobaan untuk menghapus outliers menggunakan IQR tidak membuahkan hasil yang baik, maka kita akan tetap menggunakan data yang lama

## Univariate Analysis
"""

n_cols = 2
n_rows = (len(numericals) + 1) // n_cols

plt.figure(figsize=(12, 4 * n_rows))

for idx, col in enumerate(numericals, 1):
    plt.subplot(n_rows, n_cols, idx)
    sns.histplot(df[col], kde=True)
    plt.title(f'Univariate Analysis - {col}')
    plt.xlabel(col)
    plt.ylabel('Frequency')

plt.tight_layout()
plt.show()

"""Berikut adalah hasil analisa histogram diatas:

- N (**Nitrogen**): Distribusi nitogres condong ke kiri dengan mayoritas nilai berada di bawah 50
- P (**Fosforus**): Distribusi fosforus menyebar lebih merata dengan puncak di nilai sekitar 60 dan terdapat lonjakan pada nilai diatas 120
- K (**Potasium**): Distribusi potasium condong ke kiri dengan mayoritas nilai berada di bawah 50 dan terdapat nilai yang tinggi yaitu pada nilai sekitar 200
- *Temperature* (**Suhu**): Distribusi suhu simetris dan mendekati normal dengan puncak di sekitar 25 derajat celcius.
- *Humidity* (**Kelembaban**): Distribusi kelembaban condong ke kanan dengan sebagian besar data beradara di antara 60% hingga 90%.
- pH (**Keasaman Tanah**): Distribusi pH simetris dan mendekati normal dengan puncak di sekitar pH 6 dan pH 7.
- *Rainfall* (**Curah Hujan**): Distrubsi curah hujan condong ke kiri dengan mayoritas nilai berada di rentang 50mm hingan 150mm

## Multivariate Analysis (Correlation Heatmap + Pairplot)
"""

# Menampilkan correlation antar fitur numerikal

plt.figure(figsize=(10, 8))
sns.heatmap(df[numericals].corr(), annot=True, cmap='coolwarm')
plt.title('Feature Correlation Heatmap')
plt.show()

"""Dari nilai korelasi matriks diatas, fitur **K (Potasium)** dan **P (Fosforus)** mendapatkan nilai korelasi terbesar yaitu di angka `0.74`.

# Data Preparation

## Split dataset

Membagi data menjadi train 80% dan test 20%
"""

x = df.iloc[:, :-1]
y = df['label']

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state=42)

# Melihat jumlah data

print(x_train.shape)
print(y_train.shape)
print(x_test.shape)
print(y_test.shape)

"""## Normalization

Disini kita akan melakukan normalisasi data menggunakan ***MinMaxScaler***
"""

scaler = MinMaxScaler()

x_train[numericals] = scaler.fit_transform(x_train[numericals])
x_test[numericals] = scaler.fit_transform(x_test[numericals])
x_train[numericals].describe().round(4)

"""## Label Encoder

Kita akan merubah data label yang sebelumnya bertipe kategorikal menjadi numerikal terlebih dahulu.
"""

label_encoder = LabelEncoder()
y_test_encoded = label_encoder.fit_transform(y_test)
y_train_encoded = label_encoder.transform(y_train)

"""# Modeling

Pada percobaan ini, kita akan menggunakan 3 model yang berbeda. Yaitu ***RandomForestClassifier***, ***KNN***, dan ***LogisticRegression***.

## Hyperparameter

Kita akan mencoba mencari parameter terbaik pada masing-masing model menggunakan ***GridSearch***.
"""

KNN = KNeighborsClassifier()
RF = RandomForestClassifier()
LR = LogisticRegression()

def best_param(x, y):
    algorithms = {
        'KNN': {
            'model': KNN,
            'params': {
                'n_neighbors': [3, 5, 7],
                'weights': ['uniform', 'distance'],
                'metric': ['euclidean', 'manhattan']
            }
        },
        'RandomForest': {
            'model': RF,
            'params': {
                'n_estimators': [100, 150],
                'max_depth': [None, 10, 20],
                'min_samples_split': [2, 5]
            }
        },
        'LogisticRegression': {
            'model': LR,
            'params': {
                'C': [0.1, 1.0, 10],
                'solver': ['liblinear', 'lbfgs']
            }
        }
    }

    scores = []
    for algo_name, config in algorithms.items():
        gs = GridSearchCV(config['model'], config['params'], cv=10, n_jobs=-1, scoring='accuracy')
        gs.fit(x, y)
        scores.append({
            'model': algo_name,
            'best_score': round(gs.best_score_, 4),
            'best_params': gs.best_params_
        })
        print(f"{algo_name} - Best Score: {round(gs.best_score_, 4)}")
        print(f"Best Parameters: {gs.best_params_}")
        print("-" * 50)
        print(f"Best Estimator: {gs.best_estimator_}")
        print("=" * 50)
        print("\n")
    return pd.DataFrame(scores, columns=['model', 'best_score', 'best_params'])

best_param(x, y)

"""# Evaluation

Kita akan mengevaluasi 3 model tersebut menggunakan parameter terbaik yang telah ditentukan menggunakan ***GridSearch***.
"""

# Implementasi parameter terbaik

KNN = KNeighborsClassifier(
    n_neighbors=5,
    metric='manhattan',
    weights='uniform'
)

RF = RandomForestClassifier(
    max_depth=10,
    min_samples_split=2,
    n_estimators=150
)
LR = LogisticRegression(
    C=10,
    solver='liblinear'
)

acc = pd.DataFrame(index = ['accuracy'], columns = ['KNN', 'RandomForest', 'LogisticRegression'])

# Model KNN accuracy
KNN.fit(x_train, y_train_encoded)
acc.loc['accuracy', 'KNN'] = KNN.score(x_test,y_test_encoded)

# Model RandomForest accuracy
RF.fit(x_train, y_train_encoded)
acc.loc['accuracy', 'RandomForest'] = RF.score(x_test,y_test_encoded)

# Model LogisticRegression accuracy
LR.fit(x_train, y_train_encoded)
acc.loc['accuracy', 'LogisticRegression'] = LR.score(x_test,y_test_encoded)

acc

# Dictionary of models
models = {
    'KNN': KNN,
    'RandomForest': RF,
    'LogisticRegression': LR
}

# Plot confusion matrices for each model
fig, axes = plt.subplots(1, 3, figsize=(18, 6))

for i, (name, model) in enumerate(models.items()):
    # Get predictions
    y_pred = model.predict(x_test)

    # Create confusion matrix
    cm = confusion_matrix(y_test_encoded, y_pred)

    # Plot heatmap
    sns.heatmap(cm, cmap='Blues', ax=axes[i])
    axes[i].set_title(f'Confusion Matrix - {name}')
    axes[i].set_xlabel('Predicted')
    axes[i].set_ylabel('True')

plt.suptitle('Confusion Matrices for Different Models', fontsize=16)
plt.tight_layout()
plt.show()

# Print classification reports
for name, model in models.items():
    y_pred = model.predict(x_test)
    print(f"\nClassification Report - {name}")
    print(classification_report(y_test_encoded, y_pred, target_names=label_encoder.classes_))

